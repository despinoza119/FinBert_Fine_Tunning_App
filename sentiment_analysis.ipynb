{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68d1741f-2c0f-460f-ac24-0fe123697b91",
   "metadata": {},
   "source": [
    "# FinBert Fine-Tuning and Streamlit Deploy\n",
    "\n",
    "Date: March, 2024\n",
    "\n",
    "Authors:\n",
    "- Daniel Espinoza\n",
    "- Fausto Bravo "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec283a49-a102-433c-ae86-16e8368560d0",
   "metadata": {},
   "source": [
    "**Dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3faae59-29d0-4276-b30f-06056655fb87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /Users/daniel/anaconda3/envs/data_driven/lib/python3.10/site-packages (4.66.1)\n"
     ]
    }
   ],
   "source": [
    "#%%capture\n",
    "#!pip install pandas\n",
    "#!pip install pyarrow\n",
    "#!pip install numpy\n",
    "#!pip install torch torchvision torchaudio\n",
    "#!pip install transformers\n",
    "#!pip install matplotlib\n",
    "#!pip install nltk\n",
    "#!pip install spacy\n",
    "#!pip install scikit-learn\n",
    "#!pip install tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d04969-0f47-4b3d-9adb-a7835c4fb0e7",
   "metadata": {},
   "source": [
    "**Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e68a2256-5ede-42b5-a8ce-a4ed1979e319",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daniel/anaconda3/envs/data_driven/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# General\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Tokenization\n",
    "import spacy\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from spacy.lang.en import English\n",
    "\n",
    "# Vectorization\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Models\n",
    "# Base Model - Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "#Base Model - Other Models\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Transformers Model\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertForSequenceClassification,BertTokenizer\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
    "\n",
    "# Evaluation Metrics\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241bc278-1983-4043-afb2-2b6b7a40be00",
   "metadata": {},
   "source": [
    "**Import data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8954c376-a28d-4c16-a065-949ad3a78016",
   "metadata": {},
   "source": [
    "- Twitter Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a7fa4e4-c8c2-4062-a688-40ce882d6052",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_train = pd.read_csv('./categorizacion/topic_train.csv')\n",
    "twitter_test = pd.read_csv('./categorizacion/topic_valid.csv')\n",
    "twitter = pd.concat([twitter_train,twitter_test],axis=0)\n",
    "\n",
    "# with open('./categorizacion/labels.json', 'r') as json_file:\n",
    "#     labels = pd.DataFrame(list(json.load(json_file).items()),columns=['Label','Description'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd74d680-2719-4b30-9e65-cf989dd5652b",
   "metadata": {},
   "source": [
    "- Sentiment Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b7bc99b-bb68-4e2d-b125-59b24dee187c",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_sent='./sentimiento'\n",
    "data_list = []\n",
    "\n",
    "for filename in os.listdir(directory_sent):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        file_path = os.path.join(directory_sent,filename)\n",
    "        with open(file_path,'r',encoding='latin1') as file:\n",
    "            lines = file.readlines()\n",
    "            for line in lines:\n",
    "                sentence, sentiment = line.rsplit('@',1)\n",
    "                sentiment=sentiment.strip()\n",
    "                data_list.append({'sentence':sentence,'sentiment': sentiment})\n",
    "\n",
    "sent = pd.DataFrame(data_list)\n",
    "sent = sent.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb139bee",
   "metadata": {},
   "source": [
    "- Examples\n",
    "\n",
    "**Neutral:** Tikkurila Powder Coatings has some 50 employees at its four paint plants , which generated revenues of EUR2 .4 m USD3 .3 m in 2010 \n",
    "\n",
    "**Positive:** Sales rose 10 pct to 566 mln eur on the back of strong volume and favourable currency effects \n",
    "\n",
    "**Negative:** Pharmaceuticals group Orion Corp reported a fall in its third-quarter earnings that were hit by larger expenditures on R&D and marketing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c530e67d-e70b-432d-b878-6d53ac8bb9c7",
   "metadata": {},
   "source": [
    "**Pre-processing functions**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45993af7-75b7-4993-a4bf-13037a0d0aca",
   "metadata": {},
   "source": [
    "We create our own cleaning function to get rid of stopwords and puctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b300e7ac-7b93-4249-a63b-4440f75aa7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_stop_words(data):\n",
    "    stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
    "    lista = [palabra for palabra in data if palabra not in stop_words and palabra not in string.punctuation and palabra != '``']\n",
    "    return lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5bdcf6d4-b4dc-40ea-a4e0-2e8f9bca6ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing Text\n",
    "sent_base=sent.copy()\n",
    "sent_base['tokenized_sentence'] = sent_base['sentence'].apply(word_tokenize)\n",
    "sent_base['cleaned_sentence']=sent_base['tokenized_sentence'].apply(clean_stop_words)\n",
    "sent_base['processed_sentence'] = sent_base['cleaned_sentence'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# Labeling \"sentiment\" (target variable)\n",
    "value_mapping = {'negative': 1, 'neutral': 2, 'positive': 0}\n",
    "sent_base.loc[:, 'sentiment_numeric'] = sent_base['sentiment'].map(value_mapping)\n",
    "\n",
    "# Train-Test Split (80% - 20%)\n",
    "sent_train, sent_test = train_test_split(sent_base, test_size=0.2, stratify=sent_base['sentiment'], random_state=42)\n",
    "\n",
    "# Vectorizing\n",
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "\n",
    "# train (sent_train_tfid -> features, y_sent_train -> target)\n",
    "sent_train_tfid = vectorizer.fit_transform(sent_train['processed_sentence'])\n",
    "y_sent_train=sent_train['sentiment_numeric']\n",
    "\n",
    "# test (sent_test_tfid -> features, y_sent_test -> target)\n",
    "sent_test_tfid = vectorizer.transform(sent_test['processed_sentence'])\n",
    "y_sent_test=sent_test['sentiment_numeric']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9865cfac-adbd-4dcd-af3a-406e186ab4c1",
   "metadata": {},
   "source": [
    "**Base Line Model (Logistic Regression)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ad3242c7-0518-4db9-8b50-0b89880e0e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.73\n",
      "-----------------Logistic Regression-----------------\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.52      0.60       272\n",
      "           1       0.64      0.32      0.43       121\n",
      "           2       0.74      0.91      0.82       575\n",
      "\n",
      "    accuracy                           0.73       968\n",
      "   macro avg       0.69      0.58      0.61       968\n",
      "weighted avg       0.72      0.73      0.71       968\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression Model\n",
    "model = LogisticRegression()\n",
    "model.fit(sent_train_tfid, y_sent_train)\n",
    "\n",
    "predictions = model.predict(sent_test_tfid)\n",
    "\n",
    "accuracy = accuracy_score(y_sent_test, predictions)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(\"-----------------Logistic Regression-----------------\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_sent_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d812eb-d3ad-4681-b3da-c38a2880a150",
   "metadata": {},
   "source": [
    "**Base Line Model (Other Models)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "94db01d2-ddd7-42a6-9706-471208336f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression:\n",
      "  Training Accuracy: 0.8081095041322314\n",
      "  Test Accuracy: 0.7262396694214877\n",
      "------\n",
      "RandomForestClassifier:\n",
      "  Training Accuracy: 0.9974173553719008\n",
      "  Test Accuracy: 0.7200413223140496\n",
      "------\n",
      "SVC:\n",
      "  Training Accuracy: 0.918904958677686\n",
      "  Test Accuracy: 0.7200413223140496\n",
      "------\n",
      "MultinomialNB:\n",
      "  Training Accuracy: 0.7551652892561983\n",
      "  Test Accuracy: 0.6859504132231405\n",
      "------\n",
      "GradientBoostingClassifier:\n",
      "  Training Accuracy: 0.8083677685950413\n",
      "  Test Accuracy: 0.731404958677686\n",
      "------\n",
      "KNeighborsClassifier:\n",
      "  Training Accuracy: 0.6771694214876033\n",
      "  Test Accuracy: 0.6342975206611571\n",
      "------\n",
      "DecisionTreeClassifier:\n",
      "  Training Accuracy: 0.9974173553719008\n",
      "  Test Accuracy: 0.6580578512396694\n",
      "------\n",
      "MLPClassifier:\n",
      "  Training Accuracy: 0.9974173553719008\n",
      "  Test Accuracy: 0.6828512396694215\n",
      "------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daniel/anaconda3/envs/data_driven/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    LogisticRegression(),\n",
    "    RandomForestClassifier(),\n",
    "    SVC(),\n",
    "    MultinomialNB(),\n",
    "    GradientBoostingClassifier(),\n",
    "    KNeighborsClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "    MLPClassifier()\n",
    "]\n",
    "\n",
    "for model in models:\n",
    "    model.fit(sent_train_tfid, y_sent_train)\n",
    "    \n",
    "    y_train_pred = model.predict(sent_train_tfid)\n",
    "    train_accuracy = accuracy_score(y_sent_train, y_train_pred)\n",
    "    \n",
    "    y_test_pred = model.predict(sent_test_tfid)\n",
    "    test_accuracy = accuracy_score(y_sent_test, y_test_pred)\n",
    "    \n",
    "    print(f\"{model.__class__.__name__}:\")\n",
    "    print(f\"  Training Accuracy: {train_accuracy}\")\n",
    "    print(f\"  Test Accuracy: {test_accuracy}\")\n",
    "    print(\"------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8492391",
   "metadata": {},
   "source": [
    "### Finbert (Basic Model) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42317eda-bb64-444b-abcd-4b863c402884",
   "metadata": {},
   "source": [
    "**Initiate Model FinBert**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf9b28a-0d4c-447a-a073-a455c1465497",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"ProsusAI/finbert\")\n",
    "model = BertForSequenceClassification.from_pretrained(\"ProsusAI/finbert\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef47a9d7-9814-4440-af2a-e2d2a538963f",
   "metadata": {},
   "source": [
    "**Calculate Sentiment (FinBert)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1e149d85-8a76-44f9-8fe1-77c22c5fba05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(txt):\n",
    "    tokens = tokenizer.encode_plus(txt, add_special_tokens=False,return_tensors = 'pt')\n",
    "    outputs = model(**tokens)\n",
    "    probabilities = torch.nn.functional.softmax(outputs[0], dim=-1)\n",
    "    category = torch.argmax(probabilities).item()\n",
    "    return category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "336e8a1c-61f5-4264-a752-563b57a5f8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting a copy and encoding categorical labels\n",
    "sent_testing = sent.copy()\n",
    "value_mapping = {'negative': 1, 'neutral': 2, 'positive': 0}\n",
    "sent_testing.loc[:, 'sentiment_numeric'] = sent_testing['sentiment'].map(value_mapping)\n",
    "\n",
    "# Generating a random sample \n",
    "sent_testing_sample = sent_testing.sample(n=4840, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ded16ffc-83a4-4045-a7c3-967d8bb2e829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the model to assign sentiment\n",
    "sent_testing_sample['prediction']=sent_testing_sample['sentence'].apply(get_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "020ec334-eba7-42f2-bc13-8cf53267dd50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.78\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.63      0.68      1363\n",
      "           1       0.81      0.63      0.71       604\n",
      "           2       0.80      0.89      0.84      2873\n",
      "\n",
      "    accuracy                           0.78      4840\n",
      "   macro avg       0.78      0.71      0.74      4840\n",
      "weighted avg       0.78      0.78      0.78      4840\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 857   28  478]\n",
      " [  48  380  176]\n",
      " [ 270   60 2543]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(sent_testing_sample['sentiment_numeric'], sent_testing_sample['prediction'])\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "# Display classification report\n",
    "print('Classification Report:')\n",
    "print(classification_report(sent_testing_sample['sentiment_numeric'], sent_testing_sample['prediction']))\n",
    "\n",
    "# Display confusion matrix\n",
    "conf_matrix = confusion_matrix(sent_testing_sample['sentiment_numeric'], sent_testing_sample['prediction'])\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "733be5ee-1ed4-4a6e-b907-15152d3d2c2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_numeric</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3206</th>\n",
       "      <td>Nordea Bank AB publ holds 6.000 Alma Media sha...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2531</th>\n",
       "      <td>Includes company and brand share data by categ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4107</th>\n",
       "      <td>Commission income decreased to EUR 3.8 mn , co...</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1928</th>\n",
       "      <td>The fund at fair value will increase correspon...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1538</th>\n",
       "      <td>`` We are delighted to welcome Elisa to our Bo...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence sentiment  \\\n",
       "3206  Nordea Bank AB publ holds 6.000 Alma Media sha...   neutral   \n",
       "2531  Includes company and brand share data by categ...   neutral   \n",
       "4107  Commission income decreased to EUR 3.8 mn , co...  negative   \n",
       "1928  The fund at fair value will increase correspon...  positive   \n",
       "1538  `` We are delighted to welcome Elisa to our Bo...  positive   \n",
       "\n",
       "      sentiment_numeric  prediction  \n",
       "3206                  2           2  \n",
       "2531                  2           2  \n",
       "4107                  1           1  \n",
       "1928                  0           1  \n",
       "1538                  0           0  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_testing_sample.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2da61d",
   "metadata": {},
   "source": [
    "### Finbert (for Streamlit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "33722d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"ProsusAI/finbert\")\n",
    "model = BertForSequenceClassification.from_pretrained(\"ProsusAI/finbert\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06228c3b",
   "metadata": {},
   "source": [
    "**Packaging the Model for easy use in the Streamlit App**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7ea190d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2b797e6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['transformer_model_tokenizer.joblib']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Package the tokenizer and model into a dictionary\n",
    "data_to_save = {\n",
    "    \"tokenizer\": tokenizer,\n",
    "    \"model\": model\n",
    "}\n",
    "\n",
    "# Save the packaged data to a file\n",
    "dump(data_to_save, 'transformer_model_tokenizer.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "33e10233",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "\n",
    "# Load the data from the file\n",
    "loaded_data = load('transformer_model_tokenizer.joblib')\n",
    "\n",
    "# Extract the tokenizer and model\n",
    "tokenizer_loaded = loaded_data[\"tokenizer\"]\n",
    "model_loaded = loaded_data[\"model\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4ad8ef",
   "metadata": {},
   "source": [
    "**Calculate Sentiment (FinBert)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "177a08fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(txt):\n",
    "    tokens = tokenizer.encode_plus(txt, add_special_tokens=False,return_tensors = 'pt')\n",
    "    outputs = model(**tokens)\n",
    "    probabilities = torch.nn.functional.softmax(outputs[0], dim=-1)\n",
    "    category = torch.argmax(probabilities).item()\n",
    "    return category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "93a163f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting a copy and encoding categorical labels\n",
    "sent_testing = twitter.copy()\n",
    "value_mapping = {'negative': 1, 'neutral': 2, 'positive': 0}\n",
    "# sent_testing.loc[:, 'sentiment_numeric'] = sent_testing['sentiment'].map(value_mapping)\n",
    "\n",
    "# Generating a random sample \n",
    "sent_testing_sample = sent_testing.sample(n=10, random_state=42)\n",
    "\n",
    "# Using the model to assign sentiment\n",
    "sent_testing_sample['prediction']=sent_testing_sample['text'].apply(get_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "426e8ffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10459</th>\n",
       "      <td>Roughly 60,000 of home deals fell through in J...</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6084</th>\n",
       "      <td>RBA Warns Unanchored Inflation Expectations Wo...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1635</th>\n",
       "      <td>Autonomy’s Electric Vehicle Subscription Now A...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1788</th>\n",
       "      <td>ICR Co-Founder and CEO Tom Ryan Named to PRWee...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16125</th>\n",
       "      <td>$SOND $SJ $JOAN - MCRB, MRSN and JOAN are amon...</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8769</th>\n",
       "      <td>VIDEO CORRECTION: From @Breakingviews: Big ban...</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15870</th>\n",
       "      <td>Coinbase pops 17% as cryptocurrencies like bit...</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7809</th>\n",
       "      <td>Greg Fleming, head of wealth adviser Rockefell...</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6223</th>\n",
       "      <td>In the latest Central Banker newsletter: How i...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12151</th>\n",
       "      <td>Chinese tech stocks advance following a report...</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label  prediction\n",
       "10459  Roughly 60,000 of home deals fell through in J...     14           2\n",
       "6084   RBA Warns Unanchored Inflation Expectations Wo...      1           1\n",
       "1635   Autonomy’s Electric Vehicle Subscription Now A...      2           2\n",
       "1788   ICR Co-Founder and CEO Tom Ryan Named to PRWee...      2           2\n",
       "16125  $SOND $SJ $JOAN - MCRB, MRSN and JOAN are amon...     19           2\n",
       "8769   VIDEO CORRECTION: From @Breakingviews: Big ban...      9           2\n",
       "15870  Coinbase pops 17% as cryptocurrencies like bit...     19           0\n",
       "7809   Greg Fleming, head of wealth adviser Rockefell...      9           2\n",
       "6223   In the latest Central Banker newsletter: How i...      1           2\n",
       "12151  Chinese tech stocks advance following a report...     15           0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_testing_sample.tail(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "80a5cd57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Apple Hospitality REIT Announces August 2022 Distribution  https://t.co/LI47CycIqo'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_testing.iloc[4116][\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c46b044-f3b2-44ba-9a98-5411deef8782",
   "metadata": {},
   "source": [
    "### Finbert (Fine-Tuning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b3efb0-b011-4bff-bd8e-288778aa9b44",
   "metadata": {},
   "source": [
    "**Calculate Sentiment (Fine Tuning - FinBert)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f05db1d-4a27-41f5-82d5-fc03e6399df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Setting a copy and encoding categorical labels\n",
    "twitter_tuning = twitter.copy()\n",
    "#value_mapping = {'negative': 1, 'neutral': 2, 'positive': 0}\n",
    "#sent_tuning.loc[:, 'sentiment_numeric'] = sent_tuning['sentiment'].map(value_mapping)\n",
    "\n",
    "# Split the dataset into train and validation sets\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(twitter_tuning['text'], twitter_tuning['label'],stratify=twitter_tuning['label'], test_size=0.2,)\n",
    "\n",
    "# Convert the texts and labels into tensors\n",
    "train_encodings = tokenizer(train_texts.tolist(), truncation=True, padding=True, max_length=128,return_tensors='pt')\n",
    "val_encodings = tokenizer(val_texts.tolist(), truncation=True, padding=True, max_length=128,return_tensors='pt')\n",
    "\n",
    "# Create attention masks\n",
    "train_masks = train_encodings['attention_mask']\n",
    "val_masks = val_encodings['attention_mask']\n",
    "\n",
    "train_inputs = train_encodings['input_ids']\n",
    "val_inputs = val_encodings['input_ids']\n",
    "\n",
    "train_labels = torch.tensor(train_labels.tolist())\n",
    "val_labels = torch.tensor(val_labels.tolist())\n",
    "\n",
    "# Create the DataLoader\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97e7d791-2339-4e84-8798-1a52b16728e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2, 16,  5,  ...,  6, 14, 18])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4a07c84-fc56-4cc7-8ae6-4ead6e27d153",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW\n",
    "train=0\n",
    "\n",
    "if train==1:\n",
    "    # Load the pre-trained BERT model for sequence classification\n",
    "    model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=20) \n",
    "    # Define optimizer and loss function\n",
    "    optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Move model to the device (GPU if available)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    \n",
    "    # Training loop\n",
    "    num_epochs = 1  # number of epochs\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        \n",
    "        # Use tqdm to display a progress bar\n",
    "        data_loader = tqdm(train_dataloader, desc=f'Epoch {epoch + 1}/{num_epochs}', unit='batch')\n",
    "    \n",
    "        for batch in data_loader:\n",
    "            inputs = {'input_ids': batch[0].to(device),\n",
    "                      'attention_mask': batch[1].to(device),\n",
    "                      'labels': batch[2].to(device)}\n",
    "    \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(**inputs)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "            # Update the progress bar with the current loss\n",
    "            data_loader.set_postfix({'Loss': loss.item()}, refresh=True)\n",
    "    \n",
    "    # Save the fine-tuned model\n",
    "    # model.save_pretrained('fine_tuned_bert_model')\n",
    "    \n",
    "    # Save the model\n",
    "    with open('fine_tuned_bert_model.pkl', 'wb') as f:\n",
    "        pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0af9b441-ddab-43ff-b30f-a748540f2652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the fine-tuned model\n",
    "with open('fine_tuned_bert_model.pkl', 'rb') as f:\n",
    "    model_fine_tuning = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e6a8d29-3a8f-4c2f-8acb-cb4f7cb03211",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_tuned(txt):\n",
    "    tokens = tokenizer.encode_plus(txt, add_special_tokens=False,return_tensors = 'pt')\n",
    "    outputs = model_fine_tuning(**tokens)\n",
    "    probabilities = torch.nn.functional.softmax(outputs[0], dim=-1)\n",
    "    category = torch.argmax(probabilities).item()\n",
    "    return category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d605f0a0-42e2-4d88-a70b-3c3008bb7037",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_tun = pd.DataFrame({'text': val_texts, 'label': val_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed5877d7-b444-4667-a431-53ac3562c92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_tun['prediction']=df_test_tun['text'].apply(get_sentiment_tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "987a01a4-0352-4c7a-925f-72f2d14975cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.62\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        66\n",
      "           1       0.86      0.17      0.29       210\n",
      "           2       0.68      0.80      0.74       880\n",
      "           3       1.00      0.11      0.20        80\n",
      "           4       1.00      0.59      0.74        91\n",
      "           5       0.96      0.65      0.78       246\n",
      "           6       0.89      0.25      0.40       134\n",
      "           7       0.84      0.74      0.79       157\n",
      "           8       0.00      0.00      0.00        40\n",
      "           9       0.31      0.85      0.46       379\n",
      "          10       0.00      0.00      0.00        16\n",
      "          11       0.00      0.00      0.00        12\n",
      "          12       0.94      0.49      0.64       121\n",
      "          13       1.00      0.23      0.38       117\n",
      "          14       0.79      0.40      0.53       447\n",
      "          15       0.53      0.41      0.46       125\n",
      "          16       0.71      0.72      0.72       247\n",
      "          17       1.00      0.67      0.80       121\n",
      "          18       0.57      0.90      0.70       529\n",
      "          19       0.85      0.56      0.68       204\n",
      "\n",
      "    accuracy                           0.62      4222\n",
      "   macro avg       0.65      0.43      0.46      4222\n",
      "weighted avg       0.71      0.62      0.60      4222\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daniel/anaconda3/envs/data_driven/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/daniel/anaconda3/envs/data_driven/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/daniel/anaconda3/envs/data_driven/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(df_test_tun['label'], df_test_tun['prediction'])\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "# Display classification report\n",
    "print('Classification Report:')\n",
    "print(classification_report(df_test_tun['label'], df_test_tun['prediction']))\n",
    "\n",
    "# Display confusion matrix\n",
    "#conf_matrix = confusion_matrix(df_test_tun['label'], df_test_tun['prediction'])\n",
    "#print('Confusion Matrix:')\n",
    "#print(conf_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
